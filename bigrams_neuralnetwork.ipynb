{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int representation of first chars: tensor([ 0,  5, 13, 13,  1])\n",
      "Int representation of second chars: tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "###############################################\n",
    "#\n",
    "#      BIGRAM LLM build with a Neural Network\n",
    "#\n",
    "###############################################\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('names.txt', 'r') as file:\n",
    "    names = file.readlines()\n",
    "names = [name.strip().lower() for name in names] # only lowercase letters to get 26 chars\n",
    "\n",
    "SPECIAL_CH = '.'\n",
    "\n",
    "chars = sorted(list(set(''.join(names))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)} # {'a':1, 'b':2, 'c':3, ..., 'z':26}\n",
    "# print(stoi)\n",
    "stoi[SPECIAL_CH] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "# include counting the special char with the chars in the dataset - 27 total\n",
    "NUM_CHARS = len(chars + [SPECIAL_CH])\n",
    "\n",
    "# create a training set of bigrams ( x (1st char),y (2nd char) )\n",
    "\n",
    "# inputs (xs) and targets (ys)\n",
    "xs, ys = [], []\n",
    "\n",
    "for name in names[:1]:\n",
    "    chs = [SPECIAL_CH] + list(name) + [SPECIAL_CH]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1] # get the number for the char from the stoi dict\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1) # first chars\n",
    "        ys.append(ix2) # second chars\n",
    "\n",
    "# create tensors from the lists of bigrams assembled\n",
    "xs = torch.tensor(xs) # note: use lowercase tensor() not Tensor() - that one forces the dtype to be float and lowercase tensor() infers the datatype\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "print(f'Int representation of first chars: {xs}') # inputs\n",
    "print(f'Int representation of second chars: {ys}') # labels (targets)\n",
    "# When xs[i] (first chars in bigram) is entered we want ys[i] (second chars in bigram) to have a high probability: example: When 0 is entered we want 5 to have a high probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 27])\n",
      "torch.float32\n",
      "Onehot encoded inputs: tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################\n",
    "# ONE HOT ENCODING\n",
    "###################\n",
    "\n",
    "# Not ideal to pass in integers to neural networks (due to calculations on floats), so we use One Hot Encoding\n",
    "# We want float values for a nueral net so they can take on various/continuous values\n",
    "# create a vector made up of dimensions matching the integer and turn the i-th element (the integer index) into a 1\n",
    "# This vector can feed into a neural net\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# one hot encoding. Pass in the integers you want to encode. num_classes is how many elements in the vector\n",
    "xenc = F.one_hot(xs, num_classes=NUM_CHARS) # we only need 27 elements in the vector representing 26 letters of the dataset and 1 special token '.'\n",
    "print(xenc.shape) # [5,27] one row for each letter, 27 elements in each vector\n",
    "# print(xenc.dtype) # int64 - caution!\n",
    "\n",
    "# cast the returned type from one_hot() to a float (it returns int64 integers, but we need floats to feed into neural nets)\n",
    "xenc = xenc.float()\n",
    "print(xenc.dtype)\n",
    "print(f'Onehot encoded inputs: {xenc}')\n",
    "\n",
    "plt.imshow(xenc) # visualize the one hot encoded chars\n",
    "plt.show()\n",
    "\n",
    "# each row is an example that can be fed into a neural net. The appropriate bit is turned on as a 1 (yellow block) and everything else is 0 (purple blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: tensor([[-0.8483],\n",
      "        [-0.9814],\n",
      "        [ 0.6555],\n",
      "        [ 1.8274],\n",
      "        [-1.5643],\n",
      "        [ 1.0468],\n",
      "        [ 0.6342],\n",
      "        [-0.9268],\n",
      "        [-0.5834],\n",
      "        [ 2.0462],\n",
      "        [ 0.2838],\n",
      "        [-0.3499],\n",
      "        [ 0.0488],\n",
      "        [ 0.1603],\n",
      "        [-0.0943],\n",
      "        [-0.9668],\n",
      "        [ 0.7556],\n",
      "        [-1.5551],\n",
      "        [ 1.1384],\n",
      "        [-0.2670],\n",
      "        [-0.6171],\n",
      "        [ 0.7536],\n",
      "        [-0.0066],\n",
      "        [ 1.1313],\n",
      "        [-0.4115],\n",
      "        [-0.1872],\n",
      "        [-0.0638]])\n",
      "\n",
      "xenc@W: tensor([[-0.8483],\n",
      "        [ 1.0468],\n",
      "        [ 0.1603],\n",
      "        [ 0.1603],\n",
      "        [-0.9814]])\n",
      "\n",
      "turned_on_indices=(tensor([0, 1, 2, 3, 4]), tensor([ 0,  5, 13, 13,  1]))\n",
      "\n",
      "First char bit turned on (=1.0): row=0,col=0 = corresponding weight val -0.8483 = row 0 in W\n",
      "Second char bit turned on (=1.0): row=1,col=5 = corresponding weight val 1.0468 = row 5 in W\n"
     ]
    }
   ],
   "source": [
    "########## Feed into Neurons ##############\n",
    "\n",
    "### How matrix multiplication works ###\n",
    "\n",
    "# Define the weights - use random nums\n",
    "W = torch.randn((NUM_CHARS,1)) # normally distributed numbers - most will be around 0, and the tails are thin around magnitude of 3,-3\n",
    "print(f'Weights: {W}\\n') # Column vector of 27 (NUM_CHARS) numbers - these will be multiplied by the inputs\n",
    "\n",
    "# multiply the encoded inputs by the weights using matrix multiplication\n",
    "print(f'xenc@W: {xenc @ W}\\n')\n",
    "\n",
    "# matrix multiplication of [5, 27] @ [27, 1] takes the 27 cols of input bits (per row) and multiplies by the 27 rows of W (one weight copied 27 times to fill out each row) and takes the sum (dot product)\n",
    "  # the col values in each of the 5 rows represent the 27 characters and which character is \"turned on\" - the bit as seen in the above xenc output\n",
    "# this shows us the five activations on this neuron depending on each of the 5 inputs\n",
    "\n",
    "turned_on_indices = torch.where(xenc>0) # first tensor = which row, second tensor = which col\n",
    "print(f'{turned_on_indices=}\\n')\n",
    "\n",
    "# Matrix multiplication goes for all the values in the xenc row, they are multplied by each col value in W in this case (since there is only 1 column each row val goes down the vals element-wise))\n",
    "  # Most of the values per row in xenc are 0 until we find the bit representing the char that is turned on. This will be a 1. and will be multiplied by the corresponding col value in W - \n",
    "  # the sum of the dotproduct will match 1xWcol_val since we only have one col in W\n",
    "# xenc[0][0] x W[0][0]\n",
    "# xenc[0][1] x W[1][0]\n",
    "# xenc[0][2] x W[2][0]\n",
    "# ...\n",
    "\n",
    "r = turned_on_indices[0]\n",
    "c = turned_on_indices[1]\n",
    "print(f'First char bit turned on (={xenc[r[0]][c[0]]}): row={r[0]},col={c[0]} = corresponding weight val {W[c[0]][0]:.4f} = row {c[0]} in W')\n",
    "print(f'Second char bit turned on (={xenc[r[1]][c[1]]}): row={r[1]},col={c[1]} = corresponding weight val {W[c[1]][0]:.4f} = row {c[1]} in W')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firing rate of 14th neuron looking at 4th input (row): -1.15359365940094\n",
      "\n",
      "xenc 4th row: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "W 14th column: tensor([-0.4910,  1.8493,  0.5872, -0.0911,  1.1150,  0.2830,  0.9598, -2.1307,\n",
      "         1.1073,  0.9683,  0.0060,  2.3248, -0.9708, -1.1536, -0.4835, -0.3690,\n",
      "        -1.3254,  2.1836,  0.2524,  1.0682, -1.1253, -0.3265,  1.8109, -0.3836,\n",
      "        -0.3129,  0.6867, -0.5146])\n",
      "Dot product of 4th input against 13th col of W: -1.15359365940094\n",
      "\n",
      "Inputs x Weights (27 neurons): tensor([[-0.0986,  0.5525, -1.8008,  1.0911, -0.5890, -0.3384,  0.6064,  1.2956,\n",
      "         -0.6839,  1.5796, -0.0926,  0.1417, -0.3951, -0.4910, -0.1217, -1.4546,\n",
      "         -0.4901,  0.9054,  0.2273,  0.0445,  0.2756,  0.3142,  0.0137,  0.0660,\n",
      "         -1.7717,  1.0799, -0.9139],\n",
      "        [ 1.3838, -1.9828, -1.2792,  1.1236, -1.0411, -1.3925,  2.4700,  0.1871,\n",
      "          0.1091,  0.1754,  0.8831,  0.7224, -0.3548,  0.2830, -1.2163,  0.9144,\n",
      "          0.3666,  0.1271,  0.4643, -0.0867,  1.3645, -0.4977,  1.8549,  0.1956,\n",
      "         -1.4439,  1.0929, -1.5778],\n",
      "        [ 0.9238,  1.2118, -0.2719,  2.1336,  0.3575,  0.0505,  0.4038,  0.3758,\n",
      "          0.1658,  0.9605, -0.5189, -0.2625, -0.2604, -1.1536,  0.6481,  1.1652,\n",
      "         -1.4493, -0.8635,  1.3909, -0.2457,  0.8287,  0.3683, -0.2599, -0.3371,\n",
      "         -0.2610,  0.2093,  0.4551],\n",
      "        [ 0.9238,  1.2118, -0.2719,  2.1336,  0.3575,  0.0505,  0.4038,  0.3758,\n",
      "          0.1658,  0.9605, -0.5189, -0.2625, -0.2604, -1.1536,  0.6481,  1.1652,\n",
      "         -1.4493, -0.8635,  1.3909, -0.2457,  0.8287,  0.3683, -0.2599, -0.3371,\n",
      "         -0.2610,  0.2093,  0.4551],\n",
      "        [ 0.7207,  0.3926,  0.5380, -0.9924, -1.2014,  0.0351, -3.1310, -0.1161,\n",
      "         -0.4648, -1.0289, -1.4830,  0.3478,  0.1346,  1.8493, -2.0671, -1.0228,\n",
      "          1.1679,  1.6492, -0.1257,  1.2126, -0.2876, -0.3507,  0.4392,  0.4866,\n",
      "          0.3728,  1.8003, -0.3330]])\n"
     ]
    }
   ],
   "source": [
    "# The above is for one neuron, but we want more neurons which represent one layer in a neural net\n",
    "\n",
    "# weights\n",
    "W = torch.randn(NUM_CHARS, NUM_CHARS) # 27x27 - first arg is the column of weight values to use, the second argument represents the number of neurons\n",
    "# [ [...weights], [...for which neuron] ] - rows = weights, cols = neurons\n",
    "\n",
    "dot_prods = xenc @ W # now we have a 5x27 matrix (the five onehot encoded inputs to the NN multiplied by  )\n",
    "\n",
    "# this shows the dot product of the third input and the 13th column of the W (weights) matrix\n",
    "print(f'Firing rate of 14th neuron looking at 4th input (row): {dot_prods[3,13]}\\n')\n",
    "# the firing rate is the dot product of that intput (the row values of xenc) multiplied by the weights (column values) for that neuron:\n",
    "print(f'xenc 4th row: {xenc[3]}\\n')\n",
    "print(f'W 14th column: {W[:,13]}')\n",
    "# print(f'Dot product of 4th input against 13th col of W: {xenc[3] @ W[:,13]}')\n",
    "print(f'Dot product of 4th input against 13th col of W: {(xenc[3] * W[:,13]).sum()}') # should match firing rate printed above\n",
    "\n",
    "### This matrix multiplication allows us to look at multiple input examples input into a layer of neurons in a neural net (i.e. 27 inputs into a layer of 27 neurons here)\n",
    "## NOTE: This layer is a linear layer (there is no bias or squashing function like tanh applied, just weights x inputs).\n",
    "        # This NN is also going to be just one layer (as simple as possible NN)\n",
    "\n",
    "print(f'\\nInputs x Weights (27 neurons): {dot_prods}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what you want the outputs of the NN layer to be (27 outputs, one per neuron in the layer)\n",
    "\n",
    "# We need a probability distribution for what the next character could be given a character input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
